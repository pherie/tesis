{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "jpg_to_matriks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pherie/tesis/blob/master/jpg_to_matriks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWreclQEA1yF",
        "colab_type": "code",
        "outputId": "fbd9154f-b5c0-4451-a557-7ff44145f074",
        "colab": {}
      },
      "source": [
        "# face detection for the 5 Celebrity Faces Dataset\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        " \n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        " \n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# enumerate files\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + filename\n",
        "\t\t# get face\n",
        "\t\tface = extract_face(path)\n",
        "\t\t# store\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces\n",
        " \n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# enumerate folders, on per class\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# skip any files that might be in the dir\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# load all faces in the subdirectory\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# create labels\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\t# store\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)\n",
        " \n",
        "# load train dataset\n",
        "trainX, trainy = load_dataset('datas/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "testX, testy = load_dataset('datas/valid/')\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('tulagi.npz', trainX, trainy, testX, testy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">loaded 15 examples for class: ferry\n",
            ">loaded 16 examples for class: heri\n",
            ">loaded 19 examples for class: jerico\n",
            ">loaded 17 examples for class: lina\n",
            ">loaded 17 examples for class: oki\n",
            ">loaded 17 examples for class: rofik\n",
            "(101, 160, 160, 3) (101,)\n",
            ">loaded 4 examples for class: ferry\n",
            ">loaded 4 examples for class: heri\n",
            ">loaded 4 examples for class: jerico\n",
            ">loaded 4 examples for class: lina\n",
            ">loaded 4 examples for class: oki\n",
            ">loaded 4 examples for class: rofik\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}